# ğŸ•·ï¸ ScraperUWU

ScraperUWU est un petit scraper web en Python.
Il prend une URL, parcourt les pages, extrait les infos avec des sÃ©lecteurs CSS, et enregistre le tout dans un dossier propre.


# ğŸ“¦ Installation

Clone le projet et installe les dÃ©pendances :

git clone https://github.com/wKrns/scraperuwu.git

cd scraperuwu

pip install -r requirements.txt



# âš™ï¸ FonctionnalitÃ©s

ğŸ” Scrape en temps rÃ©el Ã  partir dâ€™une URL donnÃ©e (via argument ou input).

ğŸŒ Crawl interne possible (reste dans le mÃªme domaine).

ğŸ“„ Pagination auto (si bouton â€œNextâ€).

ğŸ“ Sauvegarde en JSONL ou CSV.

ğŸ“‚ Chaque site scrapÃ© a son propre dossier de sortie (./output/example.com/).

ğŸ² Rotation alÃ©atoire des User-Agents.

ğŸ” Retries & gestion du rate limit.

â±ï¸ DÃ©lai entre requÃªtes pour Ã©viter de se faire bannir.


Les fichiers sont enregistrÃ©s dans :

./output/<domaine>/


# Exemple :

output/

 â””â”€â”€ example.com/
 
     â””â”€â”€ results.jsonl
     


# Discord : .krns 
feel free too add 
